"""
An√°lisis Exploratorio del Dataset Sint√©tico
Revela patrones de comportamiento y distribuciones para validar calidad de datos.
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import ast


def analyze_synthetic_dataset():
    """An√°lisis exploratorio completo del dataset sint√©tico."""
    
    print("üìä AN√ÅLISIS EXPLORATORIO DEL DATASET SINT√âTICO")
    print("=" * 55)
    
    # Cargar datos
    df = pd.read_csv("../../data/synthetic_training_data.csv")
    print(f"üìà Dataset: {len(df)} muestras, {len(df.columns)} columnas")
    
    # 1. AN√ÅLISIS TEMPORAL
    print(f"\nüïê 1. AN√ÅLISIS TEMPORAL")
    print("-" * 25)
    print(f"Distribuci√≥n por hora:")
    hour_counts = df['hour'].value_counts().sort_index()
    for hour, count in hour_counts.items():
        bar = "‚ñà" * int(count / 50)  # Escala visual
        print(f"  {hour:2d}h: {count:3d} {bar}")
    
    print(f"\nDistribuci√≥n por d√≠a de semana:")
    day_names = ['Lun', 'Mar', 'Mi√©', 'Jue', 'Vie', 'S√°b', 'Dom']
    day_counts = df['day_of_week'].value_counts().sort_index()
    for day, count in day_counts.items():
        bar = "‚ñà" * int(count / 30)
        print(f"  {day_names[day]}: {count:3d} {bar}")
    
    # 2. AN√ÅLISIS DE DISPOSITIVOS
    print(f"\nüì± 2. AN√ÅLISIS DE DISPOSITIVOS")
    print("-" * 30)
    
    # Touch vs No-touch
    touch_counts = df['touch_enabled'].value_counts()
    print(f"Touch habilitado: {touch_counts.get(True, 0)} ({touch_counts.get(True, 0)/len(df)*100:.1f}%)")
    print(f"Solo mouse/trackpad: {touch_counts.get(False, 0)} ({touch_counts.get(False, 0)/len(df)*100:.1f}%)")
    
    # Viewport sizes (categorizar)
    def categorize_viewport(row):
        width, height = row['viewport_width'], row['viewport_height']
        if width <= 768:
            return "Mobile"
        elif width <= 1024:
            return "Tablet"
        elif width <= 1920:
            return "Desktop"
        else:
            return "Large Desktop"
    
    df['device_category'] = df.apply(categorize_viewport, axis=1)
    device_counts = df['device_category'].value_counts()
    print(f"\nCategor√≠as de dispositivo:")
    for device, count in device_counts.items():
        print(f"  {device}: {count} ({count/len(df)*100:.1f}%)")
    
    # Device pixel ratio
    pixel_ratio_dist = df['device_pixel_ratio'].value_counts().sort_index()
    print(f"\nDevice Pixel Ratio:")
    for ratio, count in pixel_ratio_dist.items():
        print(f"  {ratio}x: {count}")
    
    # 3. AN√ÅLISIS DE PREFERENCIAS
    print(f"\nüé® 3. AN√ÅLISIS DE PREFERENCIAS")
    print("-" * 32)
    
    # Modo oscuro vs claro
    dark_mode_counts = df['prefers_dark_mode'].value_counts()
    print(f"Modo oscuro: {dark_mode_counts.get(True, 0)} ({dark_mode_counts.get(True, 0)/len(df)*100:.1f}%)")
    print(f"Modo claro: {dark_mode_counts.get(False, 0)} ({dark_mode_counts.get(False, 0)/len(df)*100:.1f}%)")
    
    # Densidad de usuario
    density_counts = df['user_group_density'].value_counts()
    print(f"\nDensidad de interfaz:")
    for density, count in density_counts.items():
        print(f"  {density}: {count} ({count/len(df)*100:.1f}%)")
    
    # Idiomas
    locale_counts = df['locale_preference'].value_counts()
    print(f"\nIdiomas preferidos:")
    for locale, count in locale_counts.items():
        print(f"  {locale}: {count} ({count/len(df)*100:.1f}%)")
    
    # 4. AN√ÅLISIS DE COMPORTAMIENTO
    print(f"\nüëÜ 4. AN√ÅLISIS DE COMPORTAMIENTO")
    print("-" * 35)
    
    # Estad√≠sticas de sesi√≥n
    print(f"Duraci√≥n promedio de sesi√≥n: {df['avg_session_duration'].mean():.1f} minutos")
    print(f"Clicks promedio por semana: {df['total_clicks_last_week'].mean():.1f}")
    print(f"Profundidad de scroll promedio: {df['scroll_depth_avg'].mean():.2f}")
    print(f"Tasa de error promedio: {df['error_rate_last_week'].mean():.3f}")
    
    # Distribuci√≥n de velocidad de interacci√≥n
    speed_stats = df['interaction_speed'].describe()
    print(f"\nVelocidad de interacci√≥n:")
    print(f"  M√≠nima: {speed_stats['min']:.2f}")
    print(f"  Mediana: {speed_stats['50%']:.2f}")
    print(f"  M√°xima: {speed_stats['max']:.2f}")
    
    # 5. AN√ÅLISIS DE CSS CLASSES (TARGETS)
    print(f"\nüéØ 5. AN√ÅLISIS DE TARGETS (CSS)")
    print("-" * 32)
    
    # Parsear CSS classes
    all_css_classes = []
    for css_str in df['css_classes']:
        try:
            classes = ast.literal_eval(css_str)
            all_css_classes.extend(classes)
        except:
            continue
    
    css_counter = Counter(all_css_classes)
    print(f"CSS Classes m√°s frecuentes:")
    for css_class, count in css_counter.most_common(10):
        print(f"  {css_class}: {count} ({count/len(df)*100:.1f}%)")
    
    # 6. AN√ÅLISIS DE CSS VARIABLES (TARGETS)
    print(f"\nCSS Variables (distribuci√≥n):")
    css_vars = ['--font-size-base', '--spacing-factor', '--color-primary-hue', '--border-radius', '--line-height']
    for var in css_vars:
        stats = df[var].describe()
        print(f"  {var}:")
        print(f"    Range: [{stats['min']:.3f}, {stats['max']:.3f}]")
        print(f"    Mean: {stats['mean']:.3f} ¬± {stats['std']:.3f}")
    
    # 7. CORRELACIONES INTERESANTES
    print(f"\nüîó 6. CORRELACIONES INTERESANTES")
    print("-" * 36)
    
    # Correlaci√≥n touch vs hora
    touch_by_hour = df.groupby('hour')['touch_enabled'].mean()
    peak_touch_hour = touch_by_hour.idxmax()
    print(f"Hora con m√°s uso t√°ctil: {peak_touch_hour}h ({touch_by_hour[peak_touch_hour]:.1%})")
    
    # Correlaci√≥n modo oscuro vs hora
    dark_by_hour = df.groupby('hour')['prefers_dark_mode'].mean()
    peak_dark_hour = dark_by_hour.idxmax()
    print(f"Hora con m√°s modo oscuro: {peak_dark_hour}h ({dark_by_hour[peak_dark_hour]:.1%})")
    
    # Correlaci√≥n dispositivo vs densidad
    density_by_device = df.groupby('device_category')['user_group_density'].apply(lambda x: (x == 'high').mean())
    print(f"\nPorcentaje de alta densidad por dispositivo:")
    for device, pct in density_by_device.items():
        print(f"  {device}: {pct:.1%}")
    
    # 8. CALIDAD DEL DATASET
    print(f"\n‚úÖ 7. CALIDAD DEL DATASET")
    print("-" * 28)
    
    # Valores faltantes
    missing_values = df.isnull().sum()
    if missing_values.sum() == 0:
        print("‚úÖ Sin valores faltantes")
    else:
        print(f"‚ö†Ô∏è Valores faltantes encontrados:")
        for col, missing in missing_values[missing_values > 0].items():
            print(f"  {col}: {missing}")
    
    # Valores duplicados
    duplicates = df.duplicated().sum()
    print(f"‚úÖ Filas duplicadas: {duplicates}")
    
    # Distribuciones v√°lidas
    print("‚úÖ Validaciones:")
    print(f"  Horas v√°lidas (0-23): {(df['hour'] >= 0).all() and (df['hour'] <= 23).all()}")
    print(f"  D√≠as v√°lidos (0-6): {(df['day_of_week'] >= 0).all() and (df['day_of_week'] <= 6).all()}")
    print(f"  Viewports positivos: {(df['viewport_width'] > 0).all() and (df['viewport_height'] > 0).all()}")
    print(f"  Pixel ratio v√°lido: {(df['device_pixel_ratio'] > 0).all()}")
    
    print(f"\nüéâ AN√ÅLISIS COMPLETADO")
    print(f"üìä Dataset listo para entrenamiento de modelos ML")
    
    return df


if __name__ == "__main__":
    df = analyze_synthetic_dataset()